{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/planttraits2024'\n",
    "train_images_path = '/train_images'\n",
    "test_images_path = '/test_images'\n",
    "data_dict = '/target_name_meta.tsv'\n",
    "test_data = '/test.csv'\n",
    "train_data = '/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = pd.read_csv(base_dir+data_dict, sep='\\t')\n",
    "df_train = pd.read_csv(base_dir+train_data)\n",
    "df_test = pd.read_csv(base_dir+test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X4: Stem specific density (SSD) or wood density (stem dry mass per stem fresh volume) \n",
      "X11: Leaf area per leaf dry mass (specific leaf area, SLA or 1/LMA) \n",
      "X18: Plant height \n",
      "X26: Seed dry mass \n",
      "X50: Leaf nitrogen (N) content per leaf area \n",
      "X3112: Leaf area (in case of compound leaves: leaf, undefined if petiole in- or excluded) \n"
     ]
    }
   ],
   "source": [
    "for i in range(df_dict.shape[0]):\n",
    "    print(f'{df_dict.values[i][0]}: {df_dict.values[i][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = os.listdir(base_dir+train_images_path)\n",
    "test_images = os.listdir(base_dir+train_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55489"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vars = ['X4_mean', 'X11_mean', \n",
    "               'X18_mean', 'X26_mean', \n",
    "               'X50_mean', 'X3112_mean']\n",
    "\n",
    "# X = df_train.drop(X_remove, axis=1)\n",
    "y = df_train[target_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "data loading\n",
      "7806 of 55489\r"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from PIL import ImageOps\n",
    "\n",
    "# Define a custom callback to print metrics at the end of each epoch\n",
    "class PrintEpochMetrics(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # `logs` contains all metrics at the end of an epoch\n",
    "        loss = logs.get('loss', 0)\n",
    "        mae = logs.get('mae', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "        val_mae = logs.get('val_mae', 0)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Loss={loss:.4f}, MAE={mae:.4f}, \"\n",
    "              f\"Val Loss={val_loss:.4f}, Val MAE={val_mae:.4f}\")\n",
    "\n",
    "print('starting')\n",
    "# Constants\n",
    "IMG_SIZE = (512, 512)\n",
    "NUM_CHANNELS = 3  # Assuming RGB images\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10  # You can adjust this based on your needs\n",
    "\n",
    "# Data loading and preprocessing\n",
    "def load_data(image_folder, labels, img_size):\n",
    "    # Get all image file paths\n",
    "    image_paths = glob.glob(os.path.join(image_folder, '*.jpeg'))\n",
    "    images = []\n",
    "    \n",
    "    total = len(image_paths)\n",
    "    \n",
    "    # Load and resize images\n",
    "    for i, path in enumerate(image_paths):\n",
    "        img = load_img(path)  # Load and resize the image\n",
    "#         img = ImageOps.grayscale(img)\n",
    "        img = img.resize(img_size)\n",
    "        img_array = img_to_array(img) / 255.0  # Normalize\n",
    "        images.append(img_array)\n",
    "        print(f'{i} of {total}', end='\\r')\n",
    "    \n",
    "    return np.array(images), labels\n",
    "\n",
    "print('data loading')\n",
    "# Load images and labels\n",
    "image_folder = base_dir+train_images_path+\"/\"  # Your folder containing images\n",
    "y_train = df_train[target_vars]\n",
    "\n",
    "# Ensure images and labels are in the same order\n",
    "images, labels = load_data(image_folder, y_train, IMG_SIZE)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')\n",
    "        self.pool1 = layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')\n",
    "        self.pool2 = layers.MaxPooling2D((2, 2))\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(128, activation='relu')\n",
    "        self.dense2 = layers.Dense(6, activation='linear')  # Output layer with 6 outputs\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "\n",
    "print(' Initialize the model')\n",
    "model = SimpleCNN()\n",
    "\n",
    "print('Compile the model')\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print('Training with the custom callback')\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), \n",
    "          epochs=EPOCHS, batch_size=BATCH_SIZE, \n",
    "          callbacks=[PrintEpochMetrics()])\n",
    "\n",
    "print('Predict on the validation set')\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "print('Calculate R² score')\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print('Calculate MSE and MAE')\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "print(f\"R² Score: {r2:.2f}\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "255",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
